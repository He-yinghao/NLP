{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e262e7f",
   "metadata": {},
   "source": [
    "导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3f2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhhe/miniconda3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mTransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformerModel\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from src.models.Transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038e54e",
   "metadata": {},
   "source": [
    "源语言与目标语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Data utilities ----------\n",
    "SRC_LANG = \"zh\"\n",
    "TGT_LANG = \"en\"\n",
    "\n",
    "# special tokens\n",
    "PAD = \"<pad>\"  # 填充符\n",
    "BOS = \"<sos>\"  # 句子开始符\n",
    "EOS = \"<eos>\"  # 句子结束符\n",
    "UNK = \"<unk>\"  # 未知词符\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ec7ab",
   "metadata": {},
   "source": [
    "数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aae04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Loading dataset from CSV files...\")\n",
    "dataset = load_csv_data(\n",
    "    train_path=\"/home/yhhe/project/Deep_Learning/NLP/datasets/tatoeba/train_zh_en.csv\",\n",
    "    test_path=\"/home/yhhe/project/Deep_Learning/NLP/datasets/tatoeba/test_zh_en.csv\",\n",
    ")\n",
    "\n",
    "# 分割验证集\n",
    "split_dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": split_dataset[\"train\"],\n",
    "        \"valid\": split_dataset[\"test\"],\n",
    "        \"test\": dataset[\"test\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Building vocabularies...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_basic(text: str) -> List[str]:\n",
    "    return text.lower().strip().split()\n",
    "\n",
    "\n",
    "def load_csv_data(train_path=\"train_zh_en.csv\", test_path=\"test_zh_en.csv\"):\n",
    "    \"\"\"从CSV文件加载数据集\"\"\"\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # 转换为Dataset格式\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    # 转换为DatasetDict\n",
    "    dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "    # 添加translation字段以兼容原有代码\n",
    "    def add_translation_field(example):\n",
    "        return {\n",
    "            \"translation\": {\n",
    "                SRC_LANG: example[\"中文\"],  # 根据您的CSV列名调整\n",
    "                TGT_LANG: example[\"英文\"],\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return dataset.map(add_translation_field)\n",
    "\n",
    "\n",
    "def build_vocabs(dataset, min_freq=2):\n",
    "    \"\"\"dataset: HuggingFace DatasetDict\"\"\"\n",
    "    src_counter, tgt_counter = Counter(), Counter()\n",
    "\n",
    "    for example in dataset[\"train\"]:\n",
    "        src_tokens = tokenize_basic(example[\"translation\"][SRC_LANG])\n",
    "        tgt_tokens = tokenize_basic(example[\"translation\"][TGT_LANG])\n",
    "        src_counter.update(src_tokens)\n",
    "        tgt_counter.update(tgt_tokens)\n",
    "\n",
    "    def make_vocab(counter):\n",
    "        vocab = {PAD: 0, BOS: 1, EOS: 2, UNK: 3}\n",
    "        idx = 4\n",
    "        for word, freq in counter.items():\n",
    "            if freq >= min_freq and word not in vocab:\n",
    "                vocab[word] = idx\n",
    "                idx += 1\n",
    "        # 建立反查\n",
    "        itos = {i: w for w, i in vocab.items()}\n",
    "        return vocab, itos\n",
    "\n",
    "    src_vocab, src_itos = make_vocab(src_counter)\n",
    "    tgt_vocab, tgt_itos = make_vocab(tgt_counter)\n",
    "    return (src_vocab, src_itos), (tgt_vocab, tgt_itos)\n",
    "\n",
    "\n",
    "def numericalize(vocab, tokens: List[str]) -> List[int]:\n",
    "    return [vocab[BOS]] + [vocab.get(t, vocab[UNK]) for t in tokens] + [vocab[EOS]]\n",
    "\n",
    "\n",
    "def collate_fn(batch, src_vocab, tgt_vocab, device):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for example in batch:\n",
    "        src_tok = tokenize_basic(example[\"translation\"][SRC_LANG])\n",
    "        tgt_tok = tokenize_basic(example[\"translation\"][TGT_LANG])\n",
    "        src_idxs = torch.tensor(numericalize(src_vocab, src_tok), dtype=torch.long)\n",
    "        tgt_idxs = torch.tensor(numericalize(tgt_vocab, tgt_tok), dtype=torch.long)\n",
    "        src_batch.append(src_idxs)\n",
    "        tgt_batch.append(tgt_idxs)\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=src_vocab[PAD], batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=tgt_vocab[PAD], batch_first=True)\n",
    "\n",
    "    return src_batch.to(device), tgt_batch.to(device)\n",
    "\n",
    "\n",
    "# ---------- Mask helpers ----------\n",
    "def make_src_key_padding_mask(src, pad_idx):\n",
    "    return src == pad_idx\n",
    "\n",
    "\n",
    "def make_tgt_masks(tgt, pad_idx):\n",
    "    B, T = tgt.size()\n",
    "    subsequent = torch.triu(torch.ones((T, T), dtype=torch.bool), diagonal=1)\n",
    "    pad_mask = tgt == pad_idx\n",
    "    return subsequent.to(tgt.device), pad_mask.to(tgt.device)\n",
    "\n",
    "\n",
    "# ---------- Training and evaluation ----------\n",
    "def train_epoch(\n",
    "    model, dataloader, optimizer, criterion, src_pad_idx, tgt_pad_idx, device, clip=1.0\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src_batch, tgt_batch in dataloader:\n",
    "        tgt_input = tgt_batch[:, :-1]\n",
    "        tgt_target = tgt_batch[:, 1:]\n",
    "        src_key_pad_mask = make_src_key_padding_mask(src_batch, src_pad_idx)\n",
    "        memory_mask = src_key_pad_mask.unsqueeze(1).expand(-1, tgt_input.size(1), -1)\n",
    "\n",
    "        subsequent_mask, tgt_key_pad_mask = make_tgt_masks(tgt_input, tgt_pad_idx)\n",
    "        causal = subsequent_mask.unsqueeze(0).expand(tgt_input.size(0), -1, -1)\n",
    "        tgt_mask = causal | tgt_key_pad_mask.unsqueeze(2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(\n",
    "            src_batch,\n",
    "            tgt_input,\n",
    "            src_mask=None,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=memory_mask,\n",
    "        )\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), tgt_target.reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, src_pad_idx, tgt_pad_idx, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src_batch, tgt_batch in dataloader:\n",
    "            tgt_input = tgt_batch[:, :-1]\n",
    "            tgt_target = tgt_batch[:, 1:]\n",
    "            src_key_pad_mask = make_src_key_padding_mask(src_batch, src_pad_idx)\n",
    "            memory_mask = src_key_pad_mask.unsqueeze(1).expand(\n",
    "                -1, tgt_input.size(1), -1\n",
    "            )\n",
    "\n",
    "            subsequent_mask, tgt_key_pad_mask = make_tgt_masks(tgt_input, tgt_pad_idx)\n",
    "            causal = subsequent_mask.unsqueeze(0).expand(tgt_input.size(0), -1, -1)\n",
    "            tgt_mask = causal | tgt_key_pad_mask.unsqueeze(2)\n",
    "\n",
    "            logits = model(\n",
    "                src_batch,\n",
    "                tgt_input,\n",
    "                src_mask=None,\n",
    "                tgt_mask=tgt_mask,\n",
    "                memory_mask=memory_mask,\n",
    "            )\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), tgt_target.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def greedy_decode(\n",
    "    model, src_sentence_tensor, src_vocab, tgt_vocab, tgt_itos, max_len=50, device=\"cpu\"\n",
    "):\n",
    "    model.eval()\n",
    "    pad_idx = src_vocab[PAD]\n",
    "    src_key_pad_mask = make_src_key_padding_mask(src_sentence_tensor, pad_idx)\n",
    "    memory_mask = src_key_pad_mask.unsqueeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        memory = model.encode(src_sentence_tensor.to(device), src_mask=None)\n",
    "        ys = torch.tensor([[tgt_vocab[BOS]]], dtype=torch.long, device=device)\n",
    "        for i in range(max_len - 1):\n",
    "            subsequent_mask, tgt_key_pad_mask = make_tgt_masks(ys, tgt_vocab[PAD])\n",
    "            causal = subsequent_mask.unsqueeze(0).expand(ys.size(0), -1, -1)\n",
    "            tgt_mask = causal | tgt_key_pad_mask.unsqueeze(2)\n",
    "            out = model.decode(\n",
    "                ys, memory, tgt_mask=tgt_mask, memory_mask=memory_mask.to(device)\n",
    "            )\n",
    "            prob = model.output_proj(out[:, -1, :])\n",
    "            next_word = torch.argmax(prob, dim=-1).item()\n",
    "            ys = torch.cat(\n",
    "                [ys, torch.tensor([[next_word]], dtype=torch.long, device=device)],\n",
    "                dim=1,\n",
    "            )\n",
    "            if next_word == tgt_vocab[EOS]:\n",
    "                break\n",
    "    return [tgt_itos[i] if i in tgt_itos else \"<unk>\" for i in ys.squeeze(0).tolist()]\n",
    "\n",
    "\n",
    "# ---------- Main script ----------\n",
    "def transformer_train(device_str=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    (src_vocab, src_itos), (tgt_vocab, tgt_itos) = build_vocabs(dataset, min_freq=2)\n",
    "    print(f\"Vocab sizes -> SRC: {len(src_vocab)}, TGT: {len(tgt_vocab)}\")\n",
    "\n",
    "    # Hyperparams\n",
    "    NUM_LAYERS = 2\n",
    "    EMBED_DIM = 256\n",
    "    NUM_HEADS = 4\n",
    "    FF_DIM = 512\n",
    "    BATCH_SIZE = 64\n",
    "    N_EPOCHS = 10\n",
    "    LR = 1e-3\n",
    "\n",
    "    src_pad_idx = src_vocab[PAD]\n",
    "    tgt_pad_idx = tgt_vocab[PAD]\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset[\"train\"],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda batch: collate_fn(batch, src_vocab, tgt_vocab, device),\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        dataset[\"valid\"],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda batch: collate_fn(batch, src_vocab, tgt_vocab, device),\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        dataset[\"test\"],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda batch: collate_fn(batch, src_vocab, tgt_vocab, device),\n",
    "    )\n",
    "\n",
    "    model = TransformerModel(\n",
    "        len(src_vocab),\n",
    "        len(tgt_vocab),\n",
    "        NUM_LAYERS,\n",
    "        EMBED_DIM,\n",
    "        NUM_HEADS,\n",
    "        FF_DIM,\n",
    "        max_len=100,\n",
    "        dropout=0.1,\n",
    "        pad_idx=src_pad_idx,\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_pad_idx)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, optimizer, criterion, src_pad_idx, tgt_pad_idx, device\n",
    "        )\n",
    "        valid_loss = evaluate(\n",
    "            model, valid_loader, criterion, src_pad_idx, tgt_pad_idx, device\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            f\"Epoch: {epoch:02} | Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f} | Time: {(end_time-start_time):.2f}s\"\n",
    "        )\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), \"best_transformer_mt.pt\")\n",
    "            print(\"\\tSaved best model.\")\n",
    "\n",
    "    # Test greedy decode\n",
    "    model.load_state_dict(torch.load(\"best_transformer_mt.pt\", map_location=device))\n",
    "    model.to(device)\n",
    "    test_sample = dataset[\"test\"].select(range(3))\n",
    "    for example in test_sample:\n",
    "        src_sent = example[\"translation\"][SRC_LANG]\n",
    "        tgt_sent = example[\"translation\"][TGT_LANG]\n",
    "        src_tok = tokenize_basic(src_sent)\n",
    "        src_idx = torch.tensor(\n",
    "            [\n",
    "                [src_vocab[BOS]]\n",
    "                + [src_vocab.get(t, src_vocab[UNK]) for t in src_tok]\n",
    "                + [src_vocab[EOS]]\n",
    "            ],\n",
    "            dtype=torch.long,\n",
    "        ).to(device)\n",
    "        pred_tokens = greedy_decode(\n",
    "            model, src_idx, src_vocab, tgt_vocab, tgt_itos, max_len=50, device=device\n",
    "        )\n",
    "        if EOS in pred_tokens:\n",
    "            pred_tokens = pred_tokens[1 : pred_tokens.index(EOS)]\n",
    "        else:\n",
    "            pred_tokens = pred_tokens[1:]\n",
    "        print(\"SRC:\", src_sent)\n",
    "        print(\"REF:\", tgt_sent)\n",
    "        print(\"PRED:\", \" \".join(pred_tokens))\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        type=str,\n",
    "        default=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        help=\"Device to use, e.g. 'cpu', 'cuda', 'cuda:0'\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    transformer_train(args.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
